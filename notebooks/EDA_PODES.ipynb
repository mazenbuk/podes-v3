{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c35a931",
   "metadata": {},
   "source": [
    "# Eksplorasi Data PODES 2024 - Blok V, VI, VII, X\n",
    "**Analisis Fasilitas Lingkungan, Bencana, Transportasi, dan TIK untuk Wilayah 3579**\n",
    "\n",
    "Notebook ini menganalisis data PODES 2024 untuk:\n",
    "- **Blok V**: Fasilitas Lingkungan & Perumahan (air, sanitasi, energi, sampah)\n",
    "- **Blok VI**: Bencana Alam & Mitigasi \n",
    "- **Blok VII**: Akses & Transportasi\n",
    "- **Blok X**: Teknologi Informasi & Komunikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4159eeb",
   "metadata": {},
   "source": [
    "## 1. Load & Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00518cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main PODES data\n",
    "def load_podes_file(filename):\n",
    "    \"\"\"Load PODES CSV with proper encoding and data types\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(f'../data/raw/{filename}', dtype=str, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ {filename}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå {filename} not found\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {filename}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load all PODES files\n",
    "podes_files = ['podes01_3579.csv', 'podes02_3579.csv', 'podes03_3579.csv', 'podes04_3579.csv']\n",
    "podes_dfs = []\n",
    "\n",
    "for file in podes_files:\n",
    "    df = load_podes_file(file)\n",
    "    if not df.empty:\n",
    "        podes_dfs.append(df)\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(podes_dfs)} PODES files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1408ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all PODES data\n",
    "if podes_dfs:\n",
    "    # Start with first dataframe\n",
    "    df_merged = podes_dfs[0].copy()\n",
    "    \n",
    "    # Merge with other dataframes\n",
    "    for i, df in enumerate(podes_dfs[1:], 1):\n",
    "        if 'IDDESA' in df.columns:\n",
    "            # Merge on IDDESA\n",
    "            before_merge = df_merged.shape\n",
    "            df_merged = df_merged.merge(df, on='IDDESA', how='outer', suffixes=('', f'_dup{i}'))\n",
    "            after_merge = df_merged.shape\n",
    "            \n",
    "            # Remove duplicate columns\n",
    "            dup_cols = [col for col in df_merged.columns if f'_dup{i}' in col]\n",
    "            df_merged = df_merged.drop(columns=dup_cols)\n",
    "            \n",
    "            print(f\"Merged with PODES{i+1}: {before_merge} ‚Üí {after_merge}\")\n",
    "    \n",
    "    print(f\"\\nüìä Final merged dataset: {df_merged.shape[0]} desa, {df_merged.shape[1]} variables\")\n",
    "else:\n",
    "    print(\"‚ùå No PODES files loaded\")\n",
    "    df_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check\n",
    "if not df_merged.empty:\n",
    "    print(\"üìã Data Quality Summary:\")\n",
    "    print(f\"Total rows: {len(df_merged):,}\")\n",
    "    print(f\"Total columns: {len(df_merged.columns):,}\")\n",
    "    \n",
    "    # Check key identity columns\n",
    "    identity_cols = ['IDDESA', 'NAMA_KEC', 'NAMA_DESA']\n",
    "    for col in identity_cols:\n",
    "        if col in df_merged.columns:\n",
    "            missing = df_merged[col].isnull().sum()\n",
    "            unique = df_merged[col].nunique()\n",
    "            print(f\"{col}: {missing} missing, {unique} unique values\")\n",
    "    \n",
    "    # Overall completeness\n",
    "    total_cells = len(df_merged) * len(df_merged.columns)\n",
    "    missing_cells = df_merged.isnull().sum().sum()\n",
    "    completeness = ((total_cells - missing_cells) / total_cells) * 100\n",
    "    print(f\"\\nData completeness: {completeness:.1f}%\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nüìù Sample data (first 3 rows):\")\n",
    "    display(df_merged[['IDDESA', 'NAMA_KEC', 'NAMA_DESA']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20d1a8",
   "metadata": {},
   "source": [
    "## 3. Load Indicators Catalog & Apply Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indicators catalog\n",
    "try:\n",
    "    catalog = pd.read_csv('../indicators_catalog.csv', encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ Indicators catalog loaded: {len(catalog)} indicators\")\n",
    "    \n",
    "    # Parse JSON mappings\n",
    "    def safe_json_parse(json_str):\n",
    "        try:\n",
    "            return json.loads(json_str) if pd.notna(json_str) else {}\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    catalog['values_map_parsed'] = catalog['values_map'].apply(safe_json_parse)\n",
    "    \n",
    "    # Show catalog summary\n",
    "    print(\"\\nüìä Catalog by theme:\")\n",
    "    theme_counts = catalog['theme'].value_counts()\n",
    "    for theme, count in theme_counts.items():\n",
    "        print(f\"{theme}: {count} indicators\")\n",
    "    \n",
    "    display(catalog[['theme', 'indicator_code', 'indicator_name', 'aggregation']].head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading catalog: {e}\")\n",
    "    catalog = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41726614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply value mappings to key variables\n",
    "def apply_mapping(series, mapping_dict):\n",
    "    \"\"\"Apply mapping with fallback to original values\"\"\"\n",
    "    if not mapping_dict:\n",
    "        return series\n",
    "    \n",
    "    mapped = series.map(mapping_dict)\n",
    "    return mapped.fillna(series)\n",
    "\n",
    "# Create labeled version of data\n",
    "df_labeled = df_merged.copy()\n",
    "\n",
    "# Apply mappings for visualization\n",
    "key_variables = ['R508A', 'R506', 'R504A', 'R504D', 'R504E', 'R505', 'R1006D', 'R1001B1']\n",
    "\n",
    "mapped_count = 0\n",
    "for var in key_variables:\n",
    "    if var in df_labeled.columns and not catalog.empty:\n",
    "        # Get mapping for this variable\n",
    "        var_row = catalog[catalog['variable'] == var]\n",
    "        if not var_row.empty:\n",
    "            mapping = var_row.iloc[0]['values_map_parsed']\n",
    "            if mapping:\n",
    "                df_labeled[f'{var}_label'] = apply_mapping(df_labeled[var], mapping)\n",
    "                mapped_count += 1\n",
    "                print(f\"‚úÖ Applied mapping to {var}\")\n",
    "\n",
    "print(f\"\\nüìä Successfully mapped {mapped_count} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed1a34",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis - Core Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2515a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze core indicators\n",
    "print(\"üîç CORE INDICATORS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "core_indicators = {\n",
    "    'R508A': 'Sumber Air Minum',\n",
    "    'R506': 'Jenis Jamban', \n",
    "    'R504D': 'TPS3R',\n",
    "    'R504E': 'Bank Sampah',\n",
    "    'R505': 'Pemilahan Sampah'\n",
    "}\n",
    "\n",
    "for var_code, var_name in core_indicators.items():\n",
    "    if var_code in df_merged.columns:\n",
    "        print(f\"\\nüìä {var_name} ({var_code}):\")\n",
    "        \n",
    "        # Basic frequency\n",
    "        freq = df_merged[var_code].value_counts().head()\n",
    "        total = df_merged[var_code].notna().sum()\n",
    "        \n",
    "        for value, count in freq.items():\n",
    "            pct = (count / total) * 100\n",
    "            print(f\"  {value}: {count} desa ({pct:.1f}%)\")\n",
    "        \n",
    "        # Missing data\n",
    "        missing = df_merged[var_code].isnull().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"  Missing: {missing} desa ({(missing/len(df_merged)*100):.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {var_name} ({var_code}): Variable not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e00347",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31caf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Sumber Air Minum Distribution\n",
    "if 'R508A' in df_labeled.columns:\n",
    "    print(\"üìä VISUALISASI 1: Distribusi Sumber Air Minum\")\n",
    "    \n",
    "    # Use labeled version if available\n",
    "    if 'R508A_label' in df_labeled.columns:\n",
    "        air_data = df_labeled['R508A_label'].value_counts()\n",
    "    else:\n",
    "        air_data = df_labeled['R508A'].value_counts()\n",
    "    \n",
    "    fig_air = px.bar(\n",
    "        x=air_data.index,\n",
    "        y=air_data.values,\n",
    "        title=\"Distribusi Sumber Air Minum Utama\",\n",
    "        labels={'x': 'Sumber Air', 'y': 'Jumlah Desa'},\n",
    "        color=air_data.values,\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig_air.update_layout(xaxis_tickangle=-45, showlegend=False)\n",
    "    fig_air.show()\n",
    "    \n",
    "    # Summary\n",
    "    total_desa = air_data.sum()\n",
    "    print(f\"Total desa dengan data: {total_desa}\")\n",
    "    print(f\"Sumber terbanyak: {air_data.index[0]} ({air_data.iloc[0]} desa, {(air_data.iloc[0]/total_desa*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Persampahan (TPS3R, Bank Sampah, Pemilahan)\n",
    "print(\"üìä VISUALISASI 2: Program Pengelolaan Sampah\")\n",
    "\n",
    "sampah_programs = ['R504D', 'R504E', 'R505']\n",
    "sampah_labels = ['TPS3R', 'Bank Sampah', 'Pemilahan']\n",
    "sampah_data = []\n",
    "\n",
    "for var, label in zip(sampah_programs, sampah_labels):\n",
    "    if var in df_merged.columns:\n",
    "        # Count \"Ada\" (kode 1)\n",
    "        ada_count = (df_merged[var] == '1').sum()\n",
    "        total_count = df_merged[var].notna().sum()\n",
    "        percentage = (ada_count / total_count * 100) if total_count > 0 else 0\n",
    "        \n",
    "        sampah_data.append({\n",
    "            'Program': label,\n",
    "            'Jumlah_Desa': ada_count,\n",
    "            'Persentase': percentage\n",
    "        })\n",
    "\n",
    "if sampah_data:\n",
    "    sampah_df = pd.DataFrame(sampah_data)\n",
    "    \n",
    "    fig_sampah = px.bar(\n",
    "        sampah_df,\n",
    "        x='Program',\n",
    "        y='Persentase',\n",
    "        title=\"Persentase Desa dengan Program Pengelolaan Sampah\",\n",
    "        labels={'Persentase': 'Persentase Desa (%)'},\n",
    "        color='Persentase',\n",
    "        color_continuous_scale='Greens',\n",
    "        text='Persentase'\n",
    "    )\n",
    "    fig_sampah.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
    "    fig_sampah.update_layout(showlegend=False)\n",
    "    fig_sampah.show()\n",
    "    \n",
    "    print(\"\\nRingkasan Program Sampah:\")\n",
    "    for _, row in sampah_df.iterrows():\n",
    "        print(f\"{row['Program']}: {row['Jumlah_Desa']} desa ({row['Persentase']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fc8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Internet & Jalan Infrastructure\n",
    "print(\"üìä VISUALISASI 3: Infrastruktur Internet & Jalan\")\n",
    "\n",
    "# Internet Quality\n",
    "if 'R1006D' in df_labeled.columns:\n",
    "    if 'R1006D_label' in df_labeled.columns:\n",
    "        internet_data = df_labeled['R1006D_label'].value_counts()\n",
    "    else:\n",
    "        internet_data = df_labeled['R1006D'].value_counts()\n",
    "    \n",
    "    fig_internet = px.pie(\n",
    "        values=internet_data.values,\n",
    "        names=internet_data.index,\n",
    "        title=\"Distribusi Kualitas Internet Seluler\"\n",
    "    )\n",
    "    fig_internet.show()\n",
    "\n",
    "# Road Surface\n",
    "if 'R1001B1' in df_labeled.columns:\n",
    "    if 'R1001B1_label' in df_labeled.columns:\n",
    "        jalan_data = df_labeled['R1001B1_label'].value_counts()\n",
    "    else:\n",
    "        jalan_data = df_labeled['R1001B1'].value_counts()\n",
    "    \n",
    "    fig_jalan = px.bar(\n",
    "        x=jalan_data.index,\n",
    "        y=jalan_data.values,\n",
    "        title=\"Distribusi Jenis Permukaan Jalan Utama\",\n",
    "        labels={'x': 'Jenis Permukaan', 'y': 'Jumlah Desa'},\n",
    "        color=jalan_data.values,\n",
    "        color_continuous_scale='Oranges'\n",
    "    )\n",
    "    fig_jalan.update_layout(xaxis_tickangle=-45, showlegend=False)\n",
    "    fig_jalan.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb3d07",
   "metadata": {},
   "source": [
    "## 6. Key Performance Indicators (KPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b112ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KPIs\n",
    "print(\"üéØ KEY PERFORMANCE INDICATORS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def calculate_kpi_rate(df, variable, true_values={'1'}):\n",
    "    \"\"\"Calculate percentage of desa with positive indicator\"\"\"\n",
    "    if variable not in df.columns:\n",
    "        return 0.0\n",
    "    \n",
    "    total = df[variable].notna().sum()\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    positive = df[variable].isin(true_values).sum()\n",
    "    return (positive / total) * 100\n",
    "\n",
    "# Define KPIs\n",
    "kpis = {\n",
    "    'TPS3R': calculate_kpi_rate(df_merged, 'R504D'),\n",
    "    'Bank Sampah': calculate_kpi_rate(df_merged, 'R504E'),\n",
    "    'Pemilahan Sampah': calculate_kpi_rate(df_merged, 'R505'),\n",
    "    'Internet Kantor Desa': calculate_kpi_rate(df_merged, 'R1005B'),\n",
    "    'BTS Tersedia': calculate_kpi_rate(df_merged, 'R1006A'),\n",
    "    'Angkutan Umum': calculate_kpi_rate(df_merged, 'R1001C')\n",
    "}\n",
    "\n",
    "# Proxy KPIs\n",
    "proxy_kpis = {}\n",
    "\n",
    "# Air Layak (bukan sungai/danau)\n",
    "if 'R508A' in df_merged.columns:\n",
    "    air_layak = df_merged['R508A'] != '6'  # 6 = Sungai/Danau\n",
    "    total_air = df_merged['R508A'].notna().sum()\n",
    "    proxy_kpis['Air Layak (proxy)'] = (air_layak.sum() / total_air * 100) if total_air > 0 else 0\n",
    "\n",
    "# Sanitasi Layak (ada jamban)\n",
    "if 'R506' in df_merged.columns:\n",
    "    sanitasi_layak = df_merged['R506'] != '4'  # 4 = Tidak Ada Jamban\n",
    "    total_sanitasi = df_merged['R506'].notna().sum()\n",
    "    proxy_kpis['Sanitasi Layak (proxy)'] = (sanitasi_layak.sum() / total_sanitasi * 100) if total_sanitasi > 0 else 0\n",
    "\n",
    "# Internet 4G+\n",
    "if 'R1006D' in df_merged.columns:\n",
    "    internet_4g = df_merged['R1006D'].isin(['1', '2'])  # 1=4G+, 2=4G\n",
    "    total_internet = df_merged['R1006D'].notna().sum()\n",
    "    proxy_kpis['Internet 4G+ (proxy)'] = (internet_4g.sum() / total_internet * 100) if total_internet > 0 else 0\n",
    "\n",
    "# Jalan Aspal/Beton\n",
    "if 'R1001B1' in df_merged.columns:\n",
    "    jalan_aspal = df_merged['R1001B1'] == '1'  # 1 = Aspal/Beton\n",
    "    total_jalan = df_merged['R1001B1'].notna().sum()\n",
    "    proxy_kpis['Jalan Aspal (proxy)'] = (jalan_aspal.sum() / total_jalan * 100) if total_jalan > 0 else 0\n",
    "\n",
    "# Combine all KPIs\n",
    "all_kpis = {**kpis, **proxy_kpis}\n",
    "\n",
    "# Display KPIs\n",
    "print(\"\\nüìä HASIL KPI:\")\n",
    "for kpi_name, kpi_value in all_kpis.items():\n",
    "    print(f\"{kpi_name}: {kpi_value:.1f}%\")\n",
    "\n",
    "# Summary statistics\n",
    "kpi_values = list(all_kpis.values())\n",
    "print(f\"\\nüìà STATISTIK KPI:\")\n",
    "print(f\"Rata-rata: {np.mean(kpi_values):.1f}%\")\n",
    "print(f\"Median: {np.median(kpi_values):.1f}%\")\n",
    "print(f\"Min: {np.min(kpi_values):.1f}%\")\n",
    "print(f\"Max: {np.max(kpi_values):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fa8e2",
   "metadata": {},
   "source": [
    "## 7. Analysis by Kecamatan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis by Kecamatan\n",
    "if 'NAMA_KEC' in df_merged.columns:\n",
    "    print(\"üó∫Ô∏è ANALISIS PER KECAMATAN\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    kecamatan_list = df_merged['NAMA_KEC'].dropna().unique()\n",
    "    print(f\"Total kecamatan: {len(kecamatan_list)}\")\n",
    "    \n",
    "    # Kecamatan summary\n",
    "    kec_summary = []\n",
    "    for kec in kecamatan_list:\n",
    "        kec_data = df_merged[df_merged['NAMA_KEC'] == kec]\n",
    "        \n",
    "        # Calculate key KPIs for this kecamatan\n",
    "        kec_kpis = {\n",
    "            'Kecamatan': kec,\n",
    "            'Jumlah_Desa': len(kec_data),\n",
    "            'TPS3R_Pct': calculate_kpi_rate(kec_data, 'R504D'),\n",
    "            'Bank_Sampah_Pct': calculate_kpi_rate(kec_data, 'R504E'),\n",
    "            'Pemilahan_Pct': calculate_kpi_rate(kec_data, 'R505'),\n",
    "            'Internet_4G_Pct': (kec_data['R1006D'].isin(['1', '2']).sum() / kec_data['R1006D'].notna().sum() * 100) if 'R1006D' in kec_data.columns and kec_data['R1006D'].notna().sum() > 0 else 0,\n",
    "            'Jalan_Aspal_Pct': calculate_kpi_rate(kec_data, 'R1001B1')\n",
    "        }\n",
    "        kec_summary.append(kec_kpis)\n",
    "    \n",
    "    kec_df = pd.DataFrame(kec_summary)\n",
    "    kec_df = kec_df.sort_values('Jumlah_Desa', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Ringkasan per Kecamatan:\")\n",
    "    display(kec_df.round(1))\n",
    "    \n",
    "    # Best and worst performing kecamatan\n",
    "    if len(kec_df) > 1:\n",
    "        # Calculate average score\n",
    "        score_cols = [col for col in kec_df.columns if col.endswith('_Pct')]\n",
    "        kec_df['Avg_Score'] = kec_df[score_cols].mean(axis=1)\n",
    "        \n",
    "        best_kec = kec_df.loc[kec_df['Avg_Score'].idxmax()]\n",
    "        worst_kec = kec_df.loc[kec_df['Avg_Score'].idxmin()]\n",
    "        \n",
    "        print(f\"\\nü•á Kecamatan Terbaik: {best_kec['Kecamatan']} (Skor: {best_kec['Avg_Score']:.1f}%)\")\n",
    "        print(f\"üîª Kecamatan Terlemah: {worst_kec['Kecamatan']} (Skor: {worst_kec['Avg_Score']:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ùå Data kecamatan tidak tersedia\")\n",
    "    kec_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc715b",
   "metadata": {},
   "source": [
    "## 8. Data Export for Streamlit Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113185bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed data folder\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "print(\"üì§ EKSPOR DATA UNTUK APLIKASI STREAMLIT\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd990733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 1: Per-desa view with core indicators\n",
    "if not df_merged.empty:\n",
    "    # Select core columns for per-desa view\n",
    "    core_cols = ['IDDESA', 'NAMA_KEC', 'NAMA_DESA']\n",
    "    \n",
    "    # Add core indicators\n",
    "    indicator_cols = ['R508A', 'R508B', 'R512', 'R506', 'R507', 'R514',\n",
    "                     'R504A', 'R504D', 'R504E', 'R505',\n",
    "                     'R501', 'R502', 'R503A',\n",
    "                     'R1005B', 'R1006A', 'R1006C', 'R1006D',\n",
    "                     'R1001A', 'R1001B1', 'R1001B2', 'R1001C',\n",
    "                     'R513', 'R515', 'R516', 'R601', 'R604']\n",
    "    \n",
    "    # Filter existing columns\n",
    "    available_cols = core_cols + [col for col in indicator_cols if col in df_merged.columns]\n",
    "    \n",
    "    per_desa_df = df_merged[available_cols].copy()\n",
    "    \n",
    "    # Add calculated proxy indicators\n",
    "    if 'R508A' in per_desa_df.columns:\n",
    "        per_desa_df['air_layak'] = (per_desa_df['R508A'] != '6').astype(int)\n",
    "    \n",
    "    if 'R506' in per_desa_df.columns:\n",
    "        per_desa_df['sanitasi_layak'] = (per_desa_df['R506'] != '4').astype(int)\n",
    "    \n",
    "    if 'R1006D' in per_desa_df.columns:\n",
    "        per_desa_df['internet_4g_plus'] = per_desa_df['R1006D'].isin(['1', '2']).astype(int)\n",
    "    \n",
    "    if 'R1001B1' in per_desa_df.columns:\n",
    "        per_desa_df['jalan_aspal'] = (per_desa_df['R1001B1'] == '1').astype(int)\n",
    "    \n",
    "    # Export\n",
    "    per_desa_df.to_csv('../data/processed/per_desa_view.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ per_desa_view.csv exported: {len(per_desa_df)} rows, {len(per_desa_df.columns)} columns\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot export per_desa_view: no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f61744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 2: Aggregated kecamatan data\n",
    "if not kec_df.empty:\n",
    "    agg_kec_df = kec_df.copy()\n",
    "    agg_kec_df.to_csv('../data/processed/agg_kecamatan.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ agg_kecamatan.csv exported: {len(agg_kec_df)} rows, {len(agg_kec_df.columns)} columns\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot export agg_kecamatan: no kecamatan data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80606f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 3: KPI summary\n",
    "kpi_summary_df = pd.DataFrame([\n",
    "    {'indicator': k, 'value': v, 'type': 'direct' if k in kpis else 'proxy'}\n",
    "    for k, v in all_kpis.items()\n",
    "])\n",
    "\n",
    "kpi_summary_df.to_csv('../data/processed/kpi_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úÖ kpi_summary.csv exported: {len(kpi_summary_df)} KPIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028cf4d2",
   "metadata": {},
   "source": [
    "## 9. Executive Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not df_merged.empty:\n",
    "    print(f\"\\nüéØ DATASET OVERVIEW:\")\n",
    "    print(f\"‚Ä¢ Total desa: {len(df_merged):,}\")\n",
    "    if 'NAMA_KEC' in df_merged.columns:\n",
    "        print(f\"‚Ä¢ Total kecamatan: {df_merged['NAMA_KEC'].nunique()}\")\n",
    "    print(f\"‚Ä¢ Total variabel: {len(df_merged.columns)}\")\n",
    "    print(f\"‚Ä¢ Kelengkapan data: {completeness:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP PERFORMERS:\")\n",
    "    top_3_kpis = sorted(all_kpis.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    for i, (kpi, value) in enumerate(top_3_kpis, 1):\n",
    "        print(f\"{i}. {kpi}: {value:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è AREAS FOR IMPROVEMENT:\")\n",
    "    bottom_3_kpis = sorted(all_kpis.items(), key=lambda x: x[1])[:3]\n",
    "    for i, (kpi, value) in enumerate(bottom_3_kpis, 1):\n",
    "        print(f\"{i}. {kpi}: {value:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    \n",
    "    # Insight 1: Persampahan\n",
    "    if all(k in all_kpis for k in ['TPS3R', 'Bank Sampah', 'Pemilahan Sampah']):\n",
    "        avg_sampah = np.mean([all_kpis['TPS3R'], all_kpis['Bank Sampah'], all_kpis['Pemilahan Sampah']])\n",
    "        if avg_sampah < 30:\n",
    "            print(f\"‚Ä¢ Pengelolaan sampah masih rendah (rata-rata {avg_sampah:.1f}%) - perlu program intensif\")\n",
    "        else:\n",
    "            print(f\"‚Ä¢ Pengelolaan sampah cukup baik (rata-rata {avg_sampah:.1f}%) - pertahankan dan tingkatkan\")\n",
    "    \n",
    "    # Insight 2: Digital divide\n",
    "    if 'Internet 4G+ (proxy)' in all_kpis:\n",
    "        internet_4g = all_kpis['Internet 4G+ (proxy)']\n",
    "        if internet_4g < 50:\n",
    "            print(f\"‚Ä¢ Kesenjangan digital masih tinggi - hanya {internet_4g:.1f}% desa dengan 4G+\")\n",
    "        else:\n",
    "            print(f\"‚Ä¢ Konektivitas internet cukup baik - {internet_4g:.1f}% desa dengan 4G+\")\n",
    "    \n",
    "    # Insight 3: Infrastructure\n",
    "    if 'Jalan Aspal (proxy)' in all_kpis:\n",
    "        jalan_aspal = all_kpis['Jalan Aspal (proxy)']\n",
    "        if jalan_aspal < 60:\n",
    "            print(f\"‚Ä¢ Infrastruktur jalan perlu perhatian - hanya {jalan_aspal:.1f}% desa dengan jalan aspal\")\n",
    "        else:\n",
    "            print(f\"‚Ä¢ Infrastruktur jalan relatif baik - {jalan_aspal:.1f}% desa dengan jalan aspal\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data telah diekspor dan siap untuk aplikasi Streamlit\")\n",
    "    print(f\"üìÅ File lokasi: data/processed/\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Tidak dapat membuat summary - data tidak tersedia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c676b",
   "metadata": {},
   "source": [
    "---\n",
    "**üìä End of EDA - PODES 2024 Wilayah 3579**\n",
    "\n",
    "Data telah dianalisis dan diekspor untuk digunakan dalam aplikasi Streamlit. File output tersedia di folder `data/processed/`:\n",
    "\n",
    "- `per_desa_view.csv`: Data detail per desa dengan indikator inti\n",
    "- `agg_kecamatan.csv`: Data agregasi per kecamatan\n",
    "- `kpi_summary.csv`: Ringkasan semua KPI\n",
    "\n",
    "**Next Steps:**\n",
    "1. Jalankan aplikasi Streamlit: `streamlit run app.py`\n",
    "2. Eksplorasi dashboard interaktif\n",
    "3. Analisis lebih mendalam per desa/kecamatan"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
